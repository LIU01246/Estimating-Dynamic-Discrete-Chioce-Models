{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Discrete Choice Model - Rust and BBL\n",
    "### Xiang Liu\n",
    "#### Department of Economics, University of Minnesota\n",
    "\n",
    "This project replicates the Nested Fixed Point Algorithm used by John Rust in his 1987 seminal paper \"Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher”. Then, I estimate Rust's results using Bajari, Benkard, and Levin (henthforce BBL, 2007) methods. \n",
    "\n",
    "I gained a lot of help from Chonghao Hao for these exercises. Credit to Hao. \n",
    "\n",
    "The codes here maybe not efficient, the Python version with JIT and GPU is coming up soon (hopefully). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Optim, Random, LinearAlgebra, ForwardDiff, Statistics, Random,Base.Threads,JLD2,Plots\n",
    "using GLM,Distributions\n",
    "using Base.Threads: @threads\n",
    "using LaTeXStrings,Latexify, Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed\n",
    "\n",
    "#### Nested Fixed Point Algorithm in Rust (1987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ll (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mutable struct Zurcher\n",
    "    # containing default parameters\n",
    "        n::Int\n",
    "        max::Int\n",
    "        beta::Float64\n",
    "        grid::Vector{Int}\n",
    "    \n",
    "        function Zurcher(;n = 90, max = 450, beta = 0.9999)\n",
    "            grid = collect(0:(n-1))\n",
    "            new(n, max, beta, grid)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    function calculate_proportions(data)\n",
    "    # calculate transition prob from data\n",
    "        unique_values = unique(data.dx1)\n",
    "        p = Vector{Float64}(undef, length(unique_values) - 1)\n",
    "        \n",
    "        for (i, val) in enumerate(unique_values[1:end-1])\n",
    "            p[i] = sum(data.dx1 .== val) / length(data.dx1)\n",
    "        end\n",
    "    \n",
    "        return p\n",
    "    end\n",
    "    \n",
    "    function transition_probs(n, p)\n",
    "    # calculate transition prob matrix\n",
    "        trpr = zeros(n, n)\n",
    "        probs = vcat(p, 1 - sum(p))\n",
    "        for (i, p) in enumerate(probs)\n",
    "            trpr += diagm(i-1 => fill(p, n-i+1))\n",
    "        end\n",
    "        trpr[:, end] .= 1 .- sum(trpr[:, 1:end-1], dims=2)\n",
    "        return trpr\n",
    "    end\n",
    "    \n",
    "    \n",
    "    struct Dta\n",
    "    # contain data for estimation\n",
    "        d::Vector{Float64}          # replace dummy, d_t\n",
    "        x::Vector{Float64}          # Odometer, x_t\n",
    "        dx1::Vector{Float64}        # Monthly mileage, dx1_t\n",
    "    end\n",
    "    \n",
    "    function readbusdata(mp, bustypes)\n",
    "        data = CSV.read(\"stata_rust_data.csv\", DataFrame);\n",
    "        # Bus id, bustype, d1 Lagged replacement dummy, d Replacement dummy, x Odometer, dx1 Monthly mileage\n",
    "        df = DataFrame(id = data[:, 1], bustype = data[:, 2], d1 = data[:, 5], x = data[:, 7])\n",
    "        # Select buses\n",
    "        if bustypes !== nothing\n",
    "            df = filter(row -> row[2] in bustypes, df)\n",
    "        end\n",
    "    \n",
    "        # Discretize odometer data into 1, 2, ..., n\n",
    "        df.x = ceil.(df.x .* mp.n / (mp.max * 1000))\n",
    "    \n",
    "        processed_groups = []\n",
    "    \n",
    "        grouped_df = groupby(df, :id)\n",
    "        for group in grouped_df\n",
    "            # Calculate d for each group\n",
    "            d = [group.d1[2:end]; 0]  # Shift and append 0\n",
    "            group.d = d \n",
    "        \n",
    "            # Calculate dx1\n",
    "            dx1 = group.x - [0; group.x[1:end-1]]\n",
    "            dx1 = dx1 .* (1 .- group.d1) .+ group.x .* group.d1\n",
    "            group.dx1 = dx1\n",
    "        \n",
    "            # Drop the first row of each group by selecting the rest of the rows\n",
    "            push!(processed_groups, group[2:end, :])\n",
    "        end\n",
    "        \n",
    "        # Combine the processed groups back into a single DataFrame\n",
    "        final_df = vcat(processed_groups...)\n",
    "        final_df = dropmissing(final_df, [:d, :x, :dx1])\n",
    "        return final_df\n",
    "    end\n",
    "    \n",
    "    # Bellman equation\n",
    "    function bellman(mp::Zurcher, ev0, c, RC, trpr)\n",
    "        x = mp.grid\n",
    "        cost = -0.001 * x * c                       # cost function\n",
    "        vx0 = cost + mp.beta * ev0                  # value of keeping\n",
    "        vx1 = -RC + cost[1] + mp.beta * ev0[1]      # value of replacing\n",
    "    \n",
    "        maxV = max.(vx0, vx1)\n",
    "        ev1 = trpr * (maxV + log.(exp.(vx0 .- maxV) + exp.(vx1 .- maxV)))\n",
    "        pr1 = 1 ./ (exp.(vx1 .- vx0) .+ 1)\n",
    "        return ev1, pr1\n",
    "    end\n",
    "    \n",
    "    function solve_vfi(c, RC, trpr, mp::Zurcher, tol = 1e-6, maxiter = 1e10)\n",
    "    # value iterated function\n",
    "        ev0 = zeros(mp.n)\n",
    "        ev1 = copy(ev0)  \n",
    "        pr1 = copy(ev0)  \n",
    "    \n",
    "        for i in 1:maxiter\n",
    "            ev1, pr1 = bellman(mp, ev0, c, RC, trpr)\n",
    "            err = maximum(abs.(ev0 - ev1))\n",
    "    \n",
    "            if err < tol\n",
    "                break\n",
    "            end\n",
    "            ev0 = ev1\n",
    "        end\n",
    "    \n",
    "        if maximum(abs.(ev0 - ev1)) >= tol\n",
    "            error(\"Failed to converge in $maxiter iterations\")\n",
    "        end\n",
    "    \n",
    "        return ev1, pr1\n",
    "    end\n",
    "    \n",
    "    \n",
    "    \n",
    "    function ll(data, mp, theta::Vector,pp=0)\n",
    "    # maximum likelihood function\n",
    "        if length(theta) >= 2\n",
    "            RC = theta[1]\n",
    "            c = theta[2]\n",
    "            if length(theta) > 2\n",
    "                p = theta[3:end]\n",
    "            else\n",
    "                p = pp\n",
    "                trpr = transition_probs(mp.n, p)\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # p = abs.(p) # used for unconstrained optimization\n",
    "        if any(x -> x < 0, p)\n",
    "            return Inf\n",
    "        end\n",
    "    \n",
    "        if sum(p) > 1.0\n",
    "            return Inf\n",
    "        end\n",
    "        \n",
    "        if length(theta) > 2\n",
    "            trpr = transition_probs(mp.n, p)\n",
    "        end\n",
    "    \n",
    "        # Solve model\n",
    "        ev0, pr = solve_vfi(c, RC, trpr,mp)\n",
    "    \n",
    "        # Evaluate likelihood function\n",
    "    \n",
    "        # 1. log likelihood regarding replacement choice\n",
    "        lp = [ pr[convert(Int, i)] for i in data.x ] # map the probabilities to the corresponding odometer x_t\n",
    "        logl = log.(lp .+ (1 .- 2 .* lp) .* data.d)\n",
    "    \n",
    "        # 2. add on log like for mileage process\n",
    "        if length(theta) > 2\n",
    "            p = vcat(p, 1 - sum(p)) # can be negative in unconstrained optimization\n",
    "            n_p = length(p) - 1\n",
    "            pr_dx = [ p[1 + convert(Int, i)] for i in data.dx1 ] \n",
    "            logl .+= log.(pr_dx)   # Monthly mileage, dx1_t\n",
    "        else\n",
    "            n_p = 0\n",
    "        end\n",
    "    \n",
    "        # Objective function (negative mean log likelihood)\n",
    "        f = sum(-logl)\n",
    "        return f,ev0\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed\n",
    "\n",
    "#### BBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj_func (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BBL Estimator\n",
    "\n",
    "# I vectorize perturbed policies and states to speed up the computation\n",
    "# The commented code is calculation for each state before vectorization \n",
    "# Did not calculate se \n",
    "###################################################################################################\n",
    "\n",
    "function get_ccp(data,mp)\n",
    "    # estimate the conditional choice probability by a logistic regression\n",
    "    # P(d=1|mileage)\n",
    "    # return prob of replacement\n",
    "        X = hcat(ones(length(data.x)), data.x)  # Adding a column of ones for the intercept\n",
    "        y = data.d\n",
    "    \n",
    "        # Fitting the model\n",
    "        my_logit = glm(X, y, Binomial(), LogitLink())\n",
    "        ccp = predict(my_logit,hcat(ones(length(mp.grid)), mp.grid))\n",
    "        return ccp\n",
    "    end\n",
    "    \n",
    "    function optimal_policy(ϵ_k, ϵ_r, optimal_policy_cutoff)\n",
    "        result = (ϵ_r .- ϵ_k) .> optimal_policy_cutoff\n",
    "        int_result = Int.(result)\n",
    "        return int_result\n",
    "    end\n",
    "    \n",
    "    function gen_path(β::Float64, optimal_cutoff::Matrix{Float64}, p::Vector{Float64}, T::Int64)\n",
    "        # β discount factor \n",
    "        # optimal_cutoff: optimal cutoff for each state \n",
    "        # p: Δ mileage transition probability\n",
    "        n, m = size(optimal_cutoff)\n",
    "        s_0 = repeat(1:n, 1, m) # Initial state for different optimal_cutff\n",
    "        sum_w1 = zeros(n,m)\n",
    "        sum_w2 = copy(sum_w1)\n",
    "        sum_w3 = copy(sum_w1)\n",
    "        dist_ϵ = Gumbel(-0.5772, 1)\n",
    "        dis_Δ = Categorical(p)\n",
    "        # Sum T periods\n",
    "        for t in 1:T\n",
    "            # Type I extreme value distribution with mean 0\n",
    "            ϵ_0 = rand(dist_ϵ, n) # can also generate n*m matrix\n",
    "            ϵ_1 = rand(dist_ϵ, n)\n",
    "            # Probability of replacement\n",
    "            cutoff_s0 = hcat([optimal_cutoff[s_0[:, j], j] for j in 1:size(optimal_cutoff, 2)]...)\n",
    "            a_0 = optimal_policy(ϵ_0, ϵ_1, cutoff_s0) # Optimal action conditional on s_0\n",
    "    \n",
    "            #  Sum of value function\n",
    "            # sum_V += a_0 * (-RC - 0.001 * θ_1 + ϵ_1) * β^t + \n",
    "            #          (1 - a_0) * (-0.001 * θ_1 * s_0 + ϵ_0) * β^t \n",
    "            sum_w1 .+= a_0 .* β^(t-1)\n",
    "            sum_w2 .+= 0.001 .* (1 .- a_0) .*s_0 .* β^(t-1)\n",
    "            sum_w3 .+= ifelse.(a_0 .== 1, ϵ_1, ϵ_0).* β^(t-1)\n",
    "            # Generate s_1\n",
    "            # generate Δ meliage\n",
    "            ΔX = rand(dis_Δ, n)\n",
    "    \n",
    "            # If replace Δx; if not Δx + s_0\n",
    "            s_1 = ifelse.(a_0 .== 1, ΔX, ΔX .- 1 .+ s_0)\n",
    "    \n",
    "            # Ensuring s_1 does not exceed max_mile\n",
    "            s_1 = min.(s_1, n)\n",
    "    \n",
    "            # Update s_0, pr_s\n",
    "            s_0 = s_1\n",
    "            \n",
    "        end\n",
    "        return sum_w1,sum_w2, sum_w3\n",
    "    end\n",
    "    \n",
    "    function gen_perturbs(ccp::Vector{Float64}, N::Int,dis = Normal(0, 1))\n",
    "        # Initialize an array to hold the perturbations\n",
    "        perturbations = Array{Float64,2}(undef, length(ccp), N)\n",
    "    \n",
    "        # Generate each perturbation\n",
    "        for i in 1:N\n",
    "            perturbations[:, i] = ccp .+ rand(dis,length(ccp))\n",
    "        end\n",
    "    \n",
    "        return perturbations\n",
    "    end\n",
    "    \n",
    "    function mean_matrixes(res::Vector{Matrix{Float64}})\n",
    "        # Caluculate mean of matrixes\n",
    "        # each col of matrix represents a perturbation, each row represents a state\n",
    "        stacked_matrices = cat(res..., dims=3)\n",
    "        average_matrix = mean(stacked_matrices, dims=3)\n",
    "        average_matrix = dropdims(average_matrix, dims=3)\n",
    "        return average_matrix\n",
    "    end \n",
    "    \n",
    "    function get_Ev(β, optimal_cutoffs, p, tol, iterations)\n",
    "        w1s = Array{Matrix{Float64}, 1}(undef, iterations) #ensure thread safe\n",
    "        w2s = Array{Matrix{Float64}, 1}(undef, iterations)\n",
    "        w3s = Array{Matrix{Float64}, 1}(undef, iterations)\n",
    "        \n",
    "        @threads for i in 1:iterations\n",
    "            sum_V = gen_path(β, optimal_cutoffs, p, tol)\n",
    "            w1s[i] = sum_V[1]\n",
    "            w2s[i] = sum_V[2]\n",
    "            w3s[i] = sum_V[3]\n",
    "        end\n",
    "        Ew1 = mean_matrixes(w1s)\n",
    "        Ew2 = mean_matrixes(w2s)\n",
    "        Ew3 = mean_matrixes(w3s)\n",
    "        return [Ew1, Ew2, Ew3]\n",
    "    end\n",
    "    \n",
    "    function value_func(sum_w1,sum_w2,sum_w3,R, θ)\n",
    "        # sum_V += a_0 * (-RC - 0.001 * θ_1 + ϵ_1) * β^t + (1 - a_0) * (-0.001 * θ_1 * s_0 + ϵ_0) * β^t\n",
    "        sum_V =  -R .* sum_w1 .- θ .* sum_w2 .+ sum_w3\n",
    "        return sum_V\n",
    "    end\n",
    "    \n",
    "    function obj_func(res,J,pars)\n",
    "        # res get from func get_Ev() has 3 matrix sum_w1,sum_w2,sum_w3\n",
    "        # J is the number of perturbations\n",
    "        R = pars[1]\n",
    "        θ = pars[2]\n",
    "        obj = 0\n",
    "        sum_w1,sum_w2,sum_w3 = res\n",
    "        for j in 2:J\n",
    "            V₀ = value_func(sum_w1[:,1],sum_w2[:,1],sum_w3[:,1],R, θ)\n",
    "            Vⱼ = value_func(sum_w1[:,j],sum_w2[:,j],sum_w3[:,j],R, θ)\n",
    "            g = min.(V₀-Vⱼ,0)\n",
    "            obj += sum(g.^2)\n",
    "        end\n",
    "        return obj\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = Zurcher();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLE_rust (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function MLE_rust(mp, data)\n",
    "    Q(e) = ll(data, mp, e)[1] # define maximum likelihood function preload data and only output the likelihood\n",
    "    theta = [0,0,0.1,0.1] # initial guess\n",
    "    theta_h = optimize(Q,theta) # optimize the function\n",
    "    θ1 = Optim.minimizer(theta_h)\n",
    "    return θ1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_group (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to process each group\n",
    "function process_group(mp, group)\n",
    "    df = readbusdata(mp,group)\n",
    "    data = Dta(df.d,df.x,df.dx1)\n",
    "\n",
    "    Q(e) = ll(data, mp, e)[1]  # define Q again to calculate Hessian matrix\n",
    "    θ1 = MLE_rust(mp, data) # optimal results\n",
    "    likelihood = -ll(data, mp, θ1)[1]  \n",
    "    \n",
    "    # use the inverse of Hessian matrix to calculate se \n",
    "    H = ForwardDiff.hessian(Q, θ1) \n",
    "    se = sqrt.(diag(inv(H)) / length(θ1))\n",
    "    N = size(df, 1)\n",
    "    return (θ1, se, likelihood, N) # estimators for table\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "#### Replicate Rust Paper table IX for beta =0.999 and 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3][4][1, 2, 3, 4]"
     ]
    }
   ],
   "source": [
    "# Test different types of bus same as rust paper Table IX\n",
    "# β = 0.999 is default \n",
    "groups = [[1,2,3], [4], [1,2,3,4]]\n",
    "\n",
    "# preset vector for multithreading\n",
    "all_data = Vector{Tuple}(undef, length(groups))\n",
    "@threads for i in 1:length(groups)\n",
    "    group = groups[i]\n",
    "    print(group)\n",
    "    # for each group get θ and se and likelihood\n",
    "    θ1, se, likelihood, N = process_group(mp, group)\n",
    "    all_data[i] = (θ1, se, likelihood, N)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3][4][1, 2, 3, 4]"
     ]
    }
   ],
   "source": [
    "# same test as above with β = 0\n",
    "groups = [[1,2,3], [4], [1,2,3,4]]\n",
    "all_data_0 = Vector{Tuple}(undef, length(groups))\n",
    "mp = Zurcher()\n",
    "mp.beta = 0\n",
    "@threads for i in 1:length(groups)\n",
    "    group = groups[i]\n",
    "    print(group)\n",
    "    θ1, se, likelihood, N = process_group(mp, group)\n",
    "    all_data_0[i] = (θ1, se, likelihood, N)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output latex (uncomment the whole cell if you want to do this)\n",
    "# function generate_latex_table_for_dataset(dataset, subtitle)\n",
    "#     groups = [\"Groups 1, 2, 3\", \"Group 4\", \"Groups 1, 2, 3, 4\"]\n",
    "#     row_titles = [\"RC\", \"\\$\\\\theta_{11}\\$\", \"\\$\\\\theta_{30}\\$\", \"\\$\\\\theta_{31}\\$\", \"Log-likelihood\", \"N\"]\n",
    "\n",
    "#     # Start the LaTeX table for this dataset\n",
    "#     latex_table = \"\"\"\n",
    "#     \\\\begin{center}\n",
    "#     \\\\textbf{$subtitle}\n",
    "#     \\\\end{center}\n",
    "#     \\\\begin{tabular}{|c|$(repeat(\"c|\", length(groups)))}\n",
    "#     \\\\hline\n",
    "#     Parameter & $(join(groups, \" & \")) \\\\\\\\ \\\\hline\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Iterate over each row (parameter)\n",
    "#     for (row_idx, row_title) in enumerate(row_titles)\n",
    "#         latex_table *= row_title\n",
    "\n",
    "#         # Add data for each group\n",
    "#         for (group_idx, data) in enumerate(dataset)\n",
    "#             θ1, se, likelihood, N = data\n",
    "#             if row_idx <= length(θ1)\n",
    "#                 # Format θ1 and se values\n",
    "#                 value = @sprintf(\"%.4f (%.4f)\", θ1[row_idx], se[row_idx])\n",
    "#             elseif row_idx == length(row_titles) - 1\n",
    "#                 # Format likelihood\n",
    "#                 value = @sprintf(\"%.4f\", likelihood)\n",
    "#             else\n",
    "#                 # Format N\n",
    "#                 value = @sprintf(\"%.4f\", N)\n",
    "#             end\n",
    "\n",
    "#             latex_table *= \" & $value\"\n",
    "#         end\n",
    "\n",
    "#         latex_table *= \" \\\\\\\\ \\\\hline\\n\"\n",
    "#     end\n",
    "\n",
    "#     # Close the table for this dataset\n",
    "#     latex_table *= \"\\\\end{tabular}\\n\"\n",
    "\n",
    "#     return latex_table\n",
    "# end\n",
    "\n",
    "# # Combine tables for all_data and all_data_0\n",
    "# latex_table_all_data = generate_latex_table_for_dataset(all_data, \"Beta is 0.9999\")\n",
    "# latex_table_all_data_0 = generate_latex_table_for_dataset(all_data_0, \"Beta is 0\")\n",
    "\n",
    "# # Full LaTeX table\n",
    "# full_latex_table = \"\"\"\n",
    "# \\\\begin{table}[ht]\n",
    "# \\\\centering\n",
    "# \\\\caption{Rust estimators for different groups}\n",
    "# $latex_table_all_data\n",
    "# \\\\vspace{1cm} % Space between tables\n",
    "# $latex_table_all_data_0\n",
    "# \\\\label{your_table_label}\n",
    "# \\\\end{table}\n",
    "# \"\"\"\n",
    "\n",
    "# open(\"rust_combined_tables.txt\", \"w\") do file\n",
    "#     write(file, full_latex_table)\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "#### Test different β values for all bus types 1,2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Tuple}:\n",
       " ([7.311520378934131, 63.4417912413077, 0.34882285806613333, 0.6394066051276539], [0.18576751359476773, 3.4618861938199155, 0.002638659859291193, 0.00265845204122969], -6061.6086520304425, 8156)\n",
       " ([7.328900199407271, 49.77852951688872, 0.3488224776588006, 0.6394069754452629], [0.18738465751583555, 2.7317181444014693, 0.0026386585420751104, 0.0026584508669865287], -6061.515177205987, 8156)\n",
       " ([7.360898054944011, 36.130264226637365, 0.3488216043653711, 0.6394077045215878], [0.1903875712872247, 2.0029636919935143, 0.0026386555714725717, 0.0026584486065551905], -6061.3455936791925, 8156)\n",
       " ([7.438389598625533, 22.520464191922056, 0.34881883990090085, 0.6394104405428604], [0.1977559067829231, 1.2776191678956994, 0.0026386461058494916, 0.0026584400260152886], -6060.949358691211, 8156)\n",
       " ([7.824363293560287, 9.047816625436504, 0.3488101975559138, 0.6394184243689262], [0.23594230661459548, 0.5640727305138774, 0.0026386016204377892, 0.00265840217780538], -6059.264101943403, 8156)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group = [1, 2, 3, 4]\n",
    "β_values = [0.1, 0.3,0.5, 0.7, 0.9]\n",
    "\n",
    "# Preallocate the results array with the proper size\n",
    "betas_data = Array{Tuple}(undef, length(β_values))\n",
    "\n",
    "# Use a thread-safe operation\n",
    "@threads for i in 1:length(β_values)\n",
    "    local_mp = deepcopy(mp)  # Create a local copy\n",
    "    local_mp.beta = β_values[i]\n",
    "    θ1, se, likelihood, N = process_group(local_mp, group)\n",
    "    betas_data[i] = (θ1, se, likelihood, N)\n",
    "end\n",
    "betas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output Latex (uncomment the whole cell if you want to do this)\n",
    "# # Row titles and β values\n",
    "# row_titles = [\"RC\", \"\\$\\\\theta_{11}\\$\", \"\\$\\\\theta_{30}\\$\", \"\\$\\\\theta_{31}\\$\", \"Log-likelihood\", \"N\"]\n",
    "\n",
    "# # Start the LaTeX table\n",
    "# latex_table = \"\"\"\n",
    "# \\\\begin{table}[ht]\n",
    "# \\\\centering\n",
    "# \\\\begin{tabular}{|c|$(repeat(\"c|\", length(β_values)))}\n",
    "# \\\\hline\n",
    "# Parameter & $(join([\"\\\\(\\\\beta\\\\)=$(β)\" for β in β_values], \" & \")) \\\\\\\\ \\\\hline\n",
    "# \"\"\"\n",
    "\n",
    "# # Iterate over each row (parameter)\n",
    "# for (row_idx, row_title) in enumerate(row_titles)\n",
    "#     latex_table *= row_title\n",
    "#     for (β_idx, data) in enumerate(betas_data)\n",
    "#         θ1, se, likelihood, N = data\n",
    "#         if row_idx <= length(θ1)\n",
    "#             value = @sprintf(\"%.4f (%.4f)\", θ1[row_idx], se[row_idx])\n",
    "#         elseif row_idx == length(row_titles) - 1\n",
    "#             value = @sprintf(\"%.4f\", likelihood)\n",
    "#         else\n",
    "#             value = @sprintf(\"%.4f\", N)\n",
    "#         end\n",
    "#         latex_table *= \" & $value\"\n",
    "#     end\n",
    "#     latex_table *= \" \\\\\\\\ \\\\hline\\n\"\n",
    "# end\n",
    "\n",
    "# # Close the LaTeX table\n",
    "# latex_table *= \"\\\\end{tabular}\\n\\\\caption{Rust_betas}\\n\\\\label{table:rust_betas}\\n\\\\end{table}\"\n",
    "\n",
    "# # Write to file\n",
    "# open(\"rust_betas.tex\", \"w\") do file\n",
    "#     write(file, latex_table)\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "\n",
    "#### Quadruple Grid Size\n",
    "Can't use NFXP to estimate transition matrix. When grids is large, it will have 11 states and yields abnormal result. \n",
    "\n",
    "Instead, I estimate mileage transition matrix from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "large_grid_MLE (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function large_grid_MLE(mp)\n",
    "    group = [1,2,3,4]\n",
    "    df = readbusdata(mp,group)\n",
    "    data = Dta(df.d,df.x,df.dx1)\n",
    "    pp = calculate_proportions(data)\n",
    "    Q(e) = ll(data, mp, e,pp)[1]\n",
    "    # can't use NXP to estimate transition matrix when n is large, it yields abornal result\n",
    "    # theta = fill(0.0, length(unique(data.dx1))+1) \n",
    "    theta = [0.0, 0.0]\n",
    "    theta_h = optimize(Q,theta)\n",
    "    θ1 = Optim.minimizer(theta_h) \n",
    "    likelihood = -ll(data, mp, θ1,pp)[1]  \n",
    "    H = ForwardDiff.hessian(Q, θ1) \n",
    "    se = sqrt.(diag(inv(H)) / length(θ1))\n",
    "    N = size(df, 1)\n",
    "    return (θ1, se, likelihood, N)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([7.323396619936107, 17.524120991742485], [0.2633492884124831, 1.3519051055337161], -306.8520665119867, 8156)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp = Zurcher(n = 360, max = 450, beta = 0)\n",
    "res0=large_grid_MLE(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:\n",
      "\n",
      "Stacktrace:\n",
      "  [1] Array\n",
      "    @ ./boot.jl:459 [inlined]\n",
      "  [2] Array\n",
      "    @ ./boot.jl:468 [inlined]\n",
      "  [3] Array\n",
      "    @ ./boot.jl:476 [inlined]\n",
      "  [4] similar\n",
      "    @ ./abstractarray.jl:841 [inlined]\n",
      "  [5] similar\n",
      "    @ ./abstractarray.jl:840 [inlined]\n",
      "  [6] similar\n",
      "    @ ./broadcast.jl:212 [inlined]\n",
      "  [7] similar\n",
      "    @ ./broadcast.jl:211 [inlined]\n",
      "  [8] copy\n",
      "    @ ./broadcast.jl:885 [inlined]\n",
      "  [9] materialize\n",
      "    @ ./broadcast.jl:860 [inlined]\n",
      " [10] bellman(mp::Zurcher, ev0::Vector{Float64}, c::Float64, RC::Float64, trpr::Matrix{Float64})\n",
      "    @ Main ~/Desktop/IO-Petrin/Rust-BBL Exercises.ipynb:89\n",
      " [11] solve_vfi(c::Float64, RC::Float64, trpr::Matrix{Float64}, mp::Zurcher, tol::Float64, maxiter::Float64)\n",
      "    @ Main ~/Desktop/IO-Petrin/Rust-BBL Exercises.ipynb:100\n",
      " [12] solve_vfi(c::Float64, RC::Float64, trpr::Matrix{Float64}, mp::Zurcher)\n",
      "    @ Main ~/Desktop/IO-Petrin/Rust-BBL Exercises.ipynb:95\n",
      " [13] ll(data::Dta, mp::Zurcher, theta::Vector{Float64}, pp::Vector{Float64})\n",
      "    @ Main ~/Desktop/IO-Petrin/Rust-BBL Exercises.ipynb:145\n",
      " [14] (::var\"#Q#73\"{Zurcher, Vector{Float64}, Dta})(e::Vector{Float64})\n",
      "    @ Main ~/Desktop/IO-Petrin/Rust-BBL Exercises.ipynb:6\n",
      " [15] value(obj::NonDifferentiable{Float64, Vector{Float64}}, x::Vector{Float64})\n",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/kavn7/src/interface.jl:19\n",
      " [16] update_state!(f::NonDifferentiable{Float64, Vector{Float64}}, state::Optim.NelderMeadState{Vector{Float64}, Float64, Vector{Float64}}, method::NelderMead{Optim.AffineSimplexer, Optim.AdaptiveParameters})\n",
      "    @ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/solvers/zeroth_order/nelder_mead.jl:224\n",
      " [17] optimize(d::NonDifferentiable{Float64, Vector{Float64}}, initial_x::Vector{Float64}, method::NelderMead{Optim.AffineSimplexer, Optim.AdaptiveParameters}, options::Optim.Options{Float64, Nothing}, state::Optim.NelderMeadState{Vector{Float64}, Float64, Vector{Float64}})\n",
      "    @ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:54\n",
      " [18] optimize(d::NonDifferentiable{Float64, Vector{Float64}}, initial_x::Vector{Float64}, method::NelderMead{Optim.AffineSimplexer, Optim.AdaptiveParameters}, options::Optim.Options{Float64, Nothing})\n",
      "    @ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:36\n",
      " [19] optimize(f::Function, initial_x::Vector{Float64}; inplace::Bool, autodiff::Symbol, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\n",
      "    @ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/interface.jl:91\n",
      " [20] optimize\n",
      "    @ ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/interface.jl:83 [inlined]\n",
      " [21] large_grid_MLE(mp::Zurcher)\n",
      "    @ Main ~/Desktop/IO-Petrin/Rust-BBL Exercises.ipynb:10\n",
      " [22] eval\n",
      "    @ ./boot.jl:368 [inlined]\n",
      " [23] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base ./loading.jl:1428\n",
      " [24] #invokelatest#2\n",
      "    @ ./essentials.jl:729 [inlined]\n",
      " [25] invokelatest\n",
      "    @ ./essentials.jl:726 [inlined]\n",
      " [26] (::VSCodeServer.var\"#214#215\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.75.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:19\n",
      " [27] withpath(f::VSCodeServer.var\"#214#215\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.75.2/scripts/packages/VSCodeServer/src/repl.jl:274\n",
      " [28] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.75.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [29] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode/extensions/julialang.language-julia-1.75.2/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [30] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.75.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:139\n",
      " [31] top-level scope\n",
      "    @ ~/.vscode/extensions/julialang.language-julia-1.75.2/scripts/notebook/notebook.jl:35"
     ]
    }
   ],
   "source": [
    "mp = Zurcher(n = 360, max = 450, beta = 0.9999)\n",
    "res1=large_grid_MLE(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output latex (uncomment the whole cell if you want to do this)\n",
    "# betas_data = [res0,res1]\n",
    "# β_values = [0.0, 0.9999]\n",
    "# # Row titles\n",
    "# row_titles = [\"RC\", \"\\$\\\\theta_{11}\\$\", \"Log-likelihood\", \"N\"]\n",
    "\n",
    "# # Start the LaTeX table\n",
    "# latex_table = \"\"\"\n",
    "# \\\\begin{table}[ht]\n",
    "# \\\\centering\n",
    "# \\\\begin{tabular}{|c|$(repeat(\"c|\", length(β_values)))}\n",
    "# \\\\hline\n",
    "# Parameter & $(join([\"\\\\(\\\\beta\\\\)=$(β)\" for β in β_values], \" & \")) \\\\\\\\ \\\\hline\n",
    "# \"\"\"\n",
    "\n",
    "# # Iterate over each row (parameter)\n",
    "# for (row_idx, row_title) in enumerate(row_titles)\n",
    "#     latex_table *= row_title\n",
    "\n",
    "#     # Add data for each β value\n",
    "#     for (β_idx, data) in enumerate(betas_data)\n",
    "#         θ1, se, likelihood, N = data\n",
    "#         if row_idx <= length(θ1)\n",
    "#             # Format θ1 and se values\n",
    "#             value = @sprintf(\"%.4f (%.4f)\", θ1[row_idx], se[row_idx])\n",
    "#         elseif row_idx == length(row_titles) - 1\n",
    "#             # Format likelihood\n",
    "#             value = @sprintf(\"%.4f\", likelihood)\n",
    "#         else\n",
    "#             # Format N\n",
    "#             value = @sprintf(\"%.4f\", N)\n",
    "#         end\n",
    "\n",
    "#         latex_table *= \" & $value\"\n",
    "#     end\n",
    "\n",
    "#     latex_table *= \" \\\\\\\\ \\\\hline\\n\"\n",
    "# end\n",
    "\n",
    "# # Close the LaTeX table\n",
    "# latex_table *= \"\\\\end{tabular}\\n\\\\caption{Rust_betas}\\n\\\\label{your_table_label}\\n\\\\end{table}\"\n",
    "# open(\"large_grid.txt\", \"w\") do file\n",
    "#     write(file, latex_table)\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBL Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 0.6394065718489456\n",
       " 0.3488229524276606\n",
       " 0.011770475723393847"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp = Zurcher()\n",
    "df = readbusdata(mp,[1,2,3,4])\n",
    "data = Dta(df.d,df.x,df.dx1)\n",
    "# Estimate mileage transition matrix\n",
    "p = calculate_proportions(data)\n",
    "push!(p, 1 - sum(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simulate_perturb (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters\n",
    "function simulate_perturb(n_I,tol;β = mp.beta,iterations = 1000,mp=mp,data=data)\n",
    "    tol =100 #making calculation faster\n",
    "    ccp = get_ccp(data, mp)\n",
    "    cutoff = log.(1 .- ccp) - log.(ccp)\n",
    "    perturbations = gen_perturbs(cutoff,n_I,Normal(0,0.5))\n",
    "    optimal_cutoffs = hcat(cutoff,perturbations)\n",
    "    res = get_Ev(β, optimal_cutoffs, p, tol, iterations)\n",
    "    return res\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: cutoff not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: cutoff not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/IO-Petrin/Rust-BBL Exercises.ipynb:3"
     ]
    }
   ],
   "source": [
    "### Plot for simulated value function when T and S are large enough\n",
    "tol= 0.99\n",
    "one_cutoff = reshape(cutoff, length(cutoff), 1)\n",
    "res = get_Ev(β,one_cutoff, p, tol, 10000)\n",
    "sum_w1,sum_w2, sum_w3 = res\n",
    "R =9.7558\n",
    "θ = 2.6275\n",
    "dt = value_func(sum_w1[:,1],sum_w2[:,1],sum_w3[:,1],R, θ)\n",
    "plot(dt, title = \"Simulated Value func Plot\", xlabel = \"s_0\", ylabel = \"Value\", legend = false)\n",
    "# savefig(\"simulated_value_function.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_theta (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_theta(res;J=n_I)\n",
    "    theta = [10.0,1.0]\n",
    "    Q(pars) = obj_func(res,J,pars)\n",
    "    theta_hat = optimize(Q,theta)\n",
    "    θ1 = Optim.minimizer(theta_hat)\n",
    "    return θ1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate latex table for estimators under different β\n",
    "β_values = [0.1, 0.3, 0.7, 0.9]\n",
    "results_df = DataFrame()\n",
    "\n",
    "# Loop through each value of β\n",
    "for b in β_values\n",
    "    res = simulate_perturb(n_I, T, β=b)\n",
    "    theta_res = get_theta(res)\n",
    "    RC, θ1 = theta_res\n",
    "    push!(results_df, (β = b, RC = RC, θ1 = θ1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### β = 0.9999\n",
    "n_I = 200\n",
    "T = 100\n",
    "res = simulate_perturb(n_I,T)\n",
    "theta0 = get_theta(res)\n",
    "push!(results_df, (β = mp.beta, RC = theta0[1], θ1 = theta0[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# β = 0\n",
    "# it equals to only 1 time period\n",
    "ccp = get_ccp(data, mp)\n",
    "cutoff = log.(1 .- ccp) - log.(ccp)\n",
    "perturbations = gen_perturbs(cutoff,200,Normal(0,0.5))\n",
    "optimal_cutoffs = hcat(cutoff,perturbations)\n",
    "@time res = get_Ev(mp.beta, optimal_cutoffs, p, 1, 1000)\n",
    "theta0 = get_theta(res,J=201)\n",
    "push!(results_df, (β = 0, RC = theta0[1], θ1 = theta0[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output Latex (uncomment the whole cell if you want to do this)\n",
    "# # Rename the columns for LaTeX formatting\n",
    "# rename!(results_df, Symbol(\"\\\\beta\") => LaTeXString(\"\\\\beta\"), :RC => LaTeXString(\"RC\"), Symbol(\"\\\\theta_1\") => LaTeXString(\"\\\\theta_1\"))\n",
    "# foreach(col -> (eltype(results_df[:, col]) <: Number) && \n",
    "#     (results_df[:, col] = round.(results_df[:, col], digits=4)), \n",
    "#     names(results_df))\n",
    "\n",
    "# open(\"BBL_betas.txt\", \"w\") do file\n",
    "#     title = \"BBL estimators for different \\$\\\\beta\\$\"\n",
    "#     header = join([\"\\\\(\\\\beta\\\\)\", \"RC\", \"\\\\(\\\\theta_{1}\\\\)\"], \" & \") * \" \\\\\\\\\\\\hline\\n\"\n",
    "\n",
    "#     # Manually construct table rows\n",
    "#     table_rows = join([join(row, \" & \") * \" \\\\\\\\\\\\hline\" for row in eachrow(results_df)], \"\\n\")\n",
    "\n",
    "#     # Full LaTeX table\n",
    "#     full_latex = \"\"\"\n",
    "#     \\\\begin{table}[h!]\n",
    "#     \\\\centering\n",
    "#     \\\\caption{$(title)}\n",
    "#     \\\\begin{tabular}{|c|c|c|}\n",
    "#     \\\\hline\n",
    "#     $header\n",
    "#     $table_rows\n",
    "#     \\\\end{tabular}\n",
    "#     \\\\end{table}\n",
    "#     \"\"\"\n",
    "    \n",
    "#     write(file, full_latex)\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadruple the Grid Size (BBL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_I = 200 # number of perturbations\n",
    "T = 1 # β=0 equal to only summing 1 period \n",
    "mp = Zurcher(n = 360)\n",
    "df = readbusdata(mp,[1,2,3,4])\n",
    "data = Dta(df.d,df.x,df.dx1)\n",
    "# Estimate mileage transition matrix\n",
    "p = calculate_proportions(data)\n",
    "push!(p, 1 - sum(p))\n",
    "\n",
    "ccp = get_ccp(data, mp)\n",
    "cutoff = log.(1 .- ccp) - log.(ccp)\n",
    "perturbations = gen_perturbs(cutoff,n_I,Normal(0,0.5))\n",
    "optimal_cutoffs = hcat(cutoff,perturbations)\n",
    "@time res = get_Ev(mp.beta, optimal_cutoffs, p, T, 1000)\n",
    "\n",
    "theta0 = get_theta(res,J=n_I+1)\n",
    "res0 = (β = 0, RC = theta0[1], θ1 = theta0[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_I = 200\n",
    "T = 100 # summing 100 periods to save time, should summing large enough periods to make β^T close to 0\n",
    "mp = Zurcher(n = 360)\n",
    "df = readbusdata(mp,[1,2,3,4])\n",
    "data = Dta(df.d,df.x,df.dx1)\n",
    "# Estimate mileage transition matrix\n",
    "p = calculate_proportions(data)\n",
    "push!(p, 1 - sum(p))\n",
    "\n",
    "ccp = get_ccp(data, mp)\n",
    "cutoff = log.(1 .- ccp) - log.(ccp)\n",
    "perturbations = gen_perturbs(cutoff,200,Normal(0,0.5))\n",
    "optimal_cutoffs = hcat(cutoff,perturbations)\n",
    "@time res = get_Ev(mp.beta, optimal_cutoffs, p, T, 1000)\n",
    "theta0 = get_theta(res,J=n_I+1)\n",
    "res1 = (β = 0.999, RC = theta0[1], θ1 = theta0[2])\n",
    "# @time gen_path(mp.beta, optimal_cutoffs, p, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output latex (uncomment the whole cell if you want to do this)\n",
    "# betas_data = [(res0.RC, res0.θ1),(res1.RC, res1.θ1)]\n",
    "# β_values = [0.0, 0.9999]\n",
    "# # Row titles\n",
    "# row_titles = [\"RC\", \"\\$\\\\theta_{1}\\$\"]\n",
    "\n",
    "# # Start the LaTeX table\n",
    "# latex_table = \"\"\"\n",
    "# \\\\begin{table}[ht]\n",
    "# \\\\centering\n",
    "# \\\\begin{tabular}{|c|$(repeat(\"c|\", length(β_values)))}\n",
    "# \\\\hline\n",
    "# Parameter & $(join([\"\\\\(\\\\beta\\\\)=$(β)\" for β in β_values], \" & \")) \\\\\\\\ \\\\hline\n",
    "# \"\"\"\n",
    "\n",
    "# # Iterate over each row (parameter)\n",
    "# for (row_idx, row_title) in enumerate(row_titles)\n",
    "#     latex_table *= row_title\n",
    "#     for data in betas_data\n",
    "#         value = \"NA\" # Default value\n",
    "#         if row_idx <= length(data)\n",
    "#             value = @sprintf(\"%.4f\", data[row_idx])\n",
    "#         end\n",
    "#         latex_table *= \" & $value\"\n",
    "#     end\n",
    "#     latex_table *= \" \\\\\\\\ \\\\hline\\n\"\n",
    "# end\n",
    "\n",
    "# # Close the LaTeX table\n",
    "# latex_table *= \"\\\\end{tabular}\\n\\\\caption{Rust_betas}\\n\\\\label{your_table_label}\\n\\\\end{table}\"\n",
    "\n",
    "# open(\"bbl_large_grid.txt\", \"w\") do file\n",
    "#     write(file, latex_table)\n",
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
